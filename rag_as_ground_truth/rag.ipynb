{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8373070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a65406a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_MODEL = \"text-embedding-3-large\"\n",
    "TOP_K = 5\n",
    "SIM_THRESHOLD = 0.75   # tune this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb75684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(texts):\n",
    "    resp = client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=texts\n",
    "    )\n",
    "    return np.array([d.embedding for d in resp.data], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d0160",
   "metadata": {},
   "source": [
    "#### domain Loading + Indicator Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c925d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_domains(path=\"../data/aacn_domain_consolidated.json\"):\n",
    "    with open(path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def flatten_indicators(domains):\n",
    "    flat = []\n",
    "    for domain in domains:\n",
    "        name = domain[\"domain_name\"]\n",
    "        for idx, indicator in enumerate(domain[\"progression_indicators\"]):\n",
    "            flat.append({\n",
    "                \"text\": indicator,\n",
    "                \"domain\": name,\n",
    "                \"indicator_index\": idx\n",
    "            })\n",
    "    return flat\n",
    "\n",
    "def build_faiss(indicators):\n",
    "    texts = [d[\"text\"] for d in indicators]\n",
    "    vecs = embed(texts)\n",
    "\n",
    "    faiss.normalize_L2(vecs)\n",
    "    index = faiss.IndexFlatIP(vecs.shape[1])\n",
    "    index.add(vecs)\n",
    "    return index, indicators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31676ea",
   "metadata": {},
   "source": [
    "#### normalized syllabi loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d914f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_syllabi(path=\"../data/syllabi.json\"):\n",
    "    with open(path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def extract_text_from_syllabus(syllabus):\n",
    "    \"\"\"\n",
    "    Recursively extract ALL text-like values from a syllabus\n",
    "    with unknown / inconsistent structure.\n",
    "    \"\"\"\n",
    "    collected = []\n",
    "\n",
    "    def crawl(value):\n",
    "        if value is None:\n",
    "            return\n",
    "\n",
    "        # Strings\n",
    "        if isinstance(value, str):\n",
    "            text = value.strip()\n",
    "            if text:\n",
    "                collected.append(text)\n",
    "\n",
    "        # Lists\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                crawl(item)\n",
    "\n",
    "        # Dicts\n",
    "        elif isinstance(value, dict):\n",
    "            for v in value.values():\n",
    "                crawl(v)\n",
    "\n",
    "        # Ignore numbers, booleans, etc.\n",
    "\n",
    "    crawl(syllabus)\n",
    "    return collected\n",
    "\n",
    "\n",
    "def syllabus_to_queries(syl):\n",
    "    \"\"\"\n",
    "    Build queries for FAISS from ANY syllabus structure.\n",
    "    \"\"\"\n",
    "    text_items = extract_text_from_syllabus(syl)\n",
    "\n",
    "    queries = []\n",
    "\n",
    "    # 1. Big combined context for coarse matching\n",
    "    full_context = \"\\n\".join(text_items)\n",
    "    queries.append(full_context)\n",
    "\n",
    "    # 2. Smaller chunks (high-signal text for fine-grained matching)\n",
    "    for item in text_items:\n",
    "        # Only keep medium-length items (good for embeddings)\n",
    "        if 20 < len(item) < 350:\n",
    "            queries.append(item)\n",
    "\n",
    "    return queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430f458",
   "metadata": {},
   "source": [
    "#### faiss + retrieve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a75182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(indicators):\n",
    "    \"\"\"\n",
    "    Build FAISS index from indicator embeddings.\n",
    "    \"\"\"\n",
    "    texts = [d[\"text\"] for d in indicators]\n",
    "    vecs = embed(texts)\n",
    "\n",
    "    # normalize for cosine similarity\n",
    "    faiss.normalize_L2(vecs)\n",
    "\n",
    "    index = faiss.IndexFlatIP(vecs.shape[1])\n",
    "    index.add(vecs)\n",
    "\n",
    "    return index\n",
    "\n",
    "def retrieve(index, indicators, query, k=TOP_K):\n",
    "    \"\"\"\n",
    "    Retrieve top-k indicators from FAISS given a query string.\n",
    "    \"\"\"\n",
    "    qvec = embed([query])\n",
    "    faiss.normalize_L2(qvec)\n",
    "\n",
    "    D, I = index.search(qvec, k)\n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        results.append((indicators[idx], float(score)))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b792dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def llm_verify_domain_coverage(syllabus_text, domain_name, indicators):\n",
    "    \"\"\"\n",
    "    Ask GPT to decide if the syllabus truly covers the domain,\n",
    "    and justify why.\n",
    "    \"\"\"\n",
    "    indicator_text = \"\\n\".join(\n",
    "        [f\"- {ind['indicator']} (sim={ind['similarity']:.2f})\" for ind in indicators]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in AACN nursing competencies.\n",
    "\n",
    "Given the following syllabus text and the retrieved AACN indicators, \n",
    "decide whether this syllabus truly covers the domain:\n",
    "\n",
    "DOMAIN: {domain_name}\n",
    "\n",
    "SYLLABUS TEXT:\n",
    "{syllabus_text}\n",
    "\n",
    "RETRIEVED INDICATORS:\n",
    "{indicator_text}\n",
    "\n",
    "Please respond in STRICT JSON format:\n",
    "\n",
    "{{\n",
    "  \"domain\": \"{domain_name}\",\n",
    "  \"covered\": true/false,\n",
    "  \"confidence\": float between 0 and 1,\n",
    "  \"justification\": \"short explanation referencing the syllabus and indicators\"\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return resp.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81dce07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_generate_syllabus_alignment(syllabus, domain_hits):\n",
    "    \"\"\"\n",
    "    Generates a final alignment report for ONE syllabus.\n",
    "    Includes:\n",
    "      - domain-level decisions\n",
    "      - justification\n",
    "      - confidence\n",
    "    \"\"\"\n",
    "    syllabus_text = \"\\n\".join(extract_text_from_syllabus(syllabus))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for domain_name, indicators in domain_hits.items():\n",
    "        llm_json = llm_verify_domain_coverage(\n",
    "            syllabus_text=syllabus_text,\n",
    "            domain_name=domain_name,\n",
    "            indicators=indicators\n",
    "        )\n",
    "        results.append(json.loads(llm_json))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c673d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_domain_coverage(index, indicators, syllabus):\n",
    "    \"\"\"\n",
    "    Retrieve indicators, group by domain, then\n",
    "    use GPT to validate coverage.\n",
    "    \"\"\"\n",
    "    queries = syllabus_to_queries(syllabus)\n",
    "    domain_hits = defaultdict(list)\n",
    "\n",
    "    for q in queries:\n",
    "        hits = retrieve(index, indicators, q)\n",
    "        for doc, sim in hits:\n",
    "            if sim >= SIM_THRESHOLD:\n",
    "                domain_hits[doc[\"domain\"]].append({\n",
    "                    \"indicator\": doc[\"text\"],\n",
    "                    \"similarity\": sim,\n",
    "                    \"query\": q\n",
    "                })\n",
    "\n",
    "    # LLM validation\n",
    "    llm_results = llm_generate_syllabus_alignment(syllabus, domain_hits)\n",
    "\n",
    "    return {\n",
    "        \"course_code\": syllabus.get(\"course_code\"),\n",
    "        \"course_name\": syllabus.get(\"course_name\"),\n",
    "        \"llm_validated_domains\": llm_results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edd737d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    domains = load_domains()\n",
    "    indicators = flatten_indicators(domains)\n",
    "    index = build_faiss_index(indicators)\n",
    "    syllabi = load_syllabi()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for syl in tqdm(syllabi):\n",
    "        res = compute_domain_coverage(index, indicators, syl)\n",
    "        results.append(res)\n",
    "\n",
    "    with open(\"llm_domain_coverage.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(\"\\nSaved LLM-validated coverage → llm_domain_coverage.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ca7aa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [04:54<00:00, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved LLM-validated coverage → llm_domain_coverage.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db49ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_domain_coverage(results):\n",
    "    \"\"\"\n",
    "    Given the LLM-validated RAG results (list of dicts),\n",
    "    compute quantitative domain coverage statistics.\n",
    "\n",
    "    Returns a dictionary with all computed analytics.\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from collections import defaultdict\n",
    "\n",
    "    # flatten results\n",
    "    course_domain_map = {}\n",
    "    domain_course_map = defaultdict(list)\n",
    "\n",
    "    all_domains = set()\n",
    "    courses = []\n",
    "\n",
    "    for entry in results:\n",
    "        course = entry[\"course_code\"]\n",
    "        courses.append(course)\n",
    "\n",
    "        validated = entry.get(\"llm_validated_domains\", [])\n",
    "\n",
    "        covered_domains = [\n",
    "            d[\"domain\"]\n",
    "            for d in validated\n",
    "            if d.get(\"covered\", False) is True\n",
    "        ]\n",
    "\n",
    "        course_domain_map[course] = covered_domains\n",
    "\n",
    "        for dom in covered_domains:\n",
    "            domain_course_map[dom].append(course)\n",
    "            all_domains.add(dom)\n",
    "\n",
    "    # Summary Metrics\n",
    "    num_courses = len(course_domain_map)\n",
    "    domain_counts = {dom: len(domain_course_map[dom]) for dom in all_domains}\n",
    "    courses_with_no_domains = [c for c, ds in course_domain_map.items() if len(ds) == 0]\n",
    "\n",
    "    # Domain Coverage Matrix (Course × Domain)\n",
    "    sorted_domains = sorted(all_domains)\n",
    "    matrix = []\n",
    "\n",
    "    for course in courses:\n",
    "        row = {\"course\": course}\n",
    "        for dom in sorted_domains:\n",
    "            row[dom] = 1 if dom in course_domain_map[course] else 0\n",
    "        matrix.append(row)\n",
    "\n",
    "    coverage_df = pd.DataFrame(matrix)\n",
    "\n",
    "    # Print Summary\n",
    "    print(\"\\n==========================\")\n",
    "    print(\" Curriculum Domain Coverage Summary\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Total courses analyzed: {num_courses}\")\n",
    "    print(f\"Domains detected across curriculum: {len(all_domains)}\")\n",
    "    print()\n",
    "\n",
    "    print(\"=== Domains Covered Frequency ===\")\n",
    "    for dom, count in sorted(domain_counts.items(), key=lambda x: -x[1]):\n",
    "        print(f\"{dom}: {count} course(s)\")\n",
    "\n",
    "    print(\"\\n=== Courses with ZERO domain coverage ===\")\n",
    "    for c in courses_with_no_domains:\n",
    "        print(f\"- {c}\")\n",
    "    print()\n",
    "\n",
    "    print(\"=== Course-by-Domain Coverage Matrix ===\")\n",
    "    print(coverage_df)\n",
    "\n",
    "    # Return structured results for further comparison/evaluation\n",
    "    return {\n",
    "        \"num_courses\": num_courses,\n",
    "        \"all_domains\": sorted_domains,\n",
    "        \"domain_counts\": domain_counts,\n",
    "        \"courses_with_no_domains\": courses_with_no_domains,\n",
    "        \"coverage_matrix\": coverage_df,\n",
    "        \"course_domain_map\": course_domain_map,\n",
    "        \"domain_course_map\": domain_course_map\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe578af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      " Curriculum Domain Coverage Summary\n",
      "==========================\n",
      "Total courses analyzed: 28\n",
      "Domains detected across curriculum: 5\n",
      "\n",
      "=== Domains Covered Frequency ===\n",
      "Domain 9: Professionalism: 3 course(s)\n",
      "Domain 6: Interprofessional Partnerships: 2 course(s)\n",
      "Domain 2: Person -Centered Care: 1 course(s)\n",
      "Domain 4: Scholarship for the Nursing Discipline: 1 course(s)\n",
      "Domain 10: Personal, Professional, and Leadership Development: 1 course(s)\n",
      "\n",
      "=== Courses with ZERO domain coverage ===\n",
      "- N279P\n",
      "- N354\n",
      "- N325\n",
      "- N277P\n",
      "- N275\n",
      "- N 344P\n",
      "- N375P\n",
      "- N356\n",
      "- N320\n",
      "- N223\n",
      "- N266\n",
      "- N244\n",
      "- N 366P\n",
      "- N127P\n",
      "- N321\n",
      "- N255C\n",
      "- N255D\n",
      "- N157P\n",
      "- N273\n",
      "- N355P\n",
      "- N274\n",
      "\n",
      "=== Course-by-Domain Coverage Matrix ===\n",
      "    course  Domain 10: Personal, Professional, and Leadership Development  \\\n",
      "0    N279P                                                  0               \n",
      "1     N310                                                  0               \n",
      "2     N354                                                  0               \n",
      "3     N325                                                  0               \n",
      "4    N277P                                                  0               \n",
      "5     N275                                                  0               \n",
      "6   N 344P                                                  0               \n",
      "7    N375P                                                  0               \n",
      "8     N356                                                  0               \n",
      "9     N320                                                  0               \n",
      "10    N223                                                  0               \n",
      "11    N266                                                  0               \n",
      "12    N244                                                  0               \n",
      "13   N325P                                                  0               \n",
      "14    N264                                                  0               \n",
      "15    N224                                                  0               \n",
      "16  N 366P                                                  0               \n",
      "17   N127P                                                  0               \n",
      "18   N 377                                                  1               \n",
      "19    N321                                                  0               \n",
      "20   N277P                                                  0               \n",
      "21   N255C                                                  0               \n",
      "22   N255D                                                  0               \n",
      "23   N157P                                                  0               \n",
      "24    N250                                                  0               \n",
      "25    N273                                                  0               \n",
      "26   N355P                                                  0               \n",
      "27    N274                                                  0               \n",
      "28   N256P                                                  0               \n",
      "\n",
      "    Domain 2: Person -Centered Care  \\\n",
      "0                                 0   \n",
      "1                                 0   \n",
      "2                                 0   \n",
      "3                                 0   \n",
      "4                                 0   \n",
      "5                                 0   \n",
      "6                                 0   \n",
      "7                                 0   \n",
      "8                                 0   \n",
      "9                                 0   \n",
      "10                                0   \n",
      "11                                0   \n",
      "12                                0   \n",
      "13                                0   \n",
      "14                                0   \n",
      "15                                0   \n",
      "16                                0   \n",
      "17                                0   \n",
      "18                                0   \n",
      "19                                0   \n",
      "20                                0   \n",
      "21                                0   \n",
      "22                                0   \n",
      "23                                0   \n",
      "24                                0   \n",
      "25                                0   \n",
      "26                                0   \n",
      "27                                0   \n",
      "28                                1   \n",
      "\n",
      "    Domain 4: Scholarship for the Nursing Discipline  \\\n",
      "0                                                  0   \n",
      "1                                                  0   \n",
      "2                                                  0   \n",
      "3                                                  0   \n",
      "4                                                  0   \n",
      "5                                                  0   \n",
      "6                                                  0   \n",
      "7                                                  0   \n",
      "8                                                  0   \n",
      "9                                                  0   \n",
      "10                                                 0   \n",
      "11                                                 0   \n",
      "12                                                 0   \n",
      "13                                                 0   \n",
      "14                                                 1   \n",
      "15                                                 0   \n",
      "16                                                 0   \n",
      "17                                                 0   \n",
      "18                                                 0   \n",
      "19                                                 0   \n",
      "20                                                 0   \n",
      "21                                                 0   \n",
      "22                                                 0   \n",
      "23                                                 0   \n",
      "24                                                 0   \n",
      "25                                                 0   \n",
      "26                                                 0   \n",
      "27                                                 0   \n",
      "28                                                 0   \n",
      "\n",
      "    Domain 6: Interprofessional Partnerships  Domain 9: Professionalism  \n",
      "0                                          0                          0  \n",
      "1                                          1                          1  \n",
      "2                                          0                          0  \n",
      "3                                          0                          0  \n",
      "4                                          0                          0  \n",
      "5                                          0                          0  \n",
      "6                                          0                          0  \n",
      "7                                          0                          0  \n",
      "8                                          0                          0  \n",
      "9                                          0                          0  \n",
      "10                                         0                          0  \n",
      "11                                         0                          0  \n",
      "12                                         0                          0  \n",
      "13                                         0                          1  \n",
      "14                                         0                          0  \n",
      "15                                         0                          1  \n",
      "16                                         0                          0  \n",
      "17                                         0                          0  \n",
      "18                                         0                          0  \n",
      "19                                         0                          0  \n",
      "20                                         0                          0  \n",
      "21                                         0                          0  \n",
      "22                                         0                          0  \n",
      "23                                         0                          0  \n",
      "24                                         1                          0  \n",
      "25                                         0                          0  \n",
      "26                                         0                          0  \n",
      "27                                         0                          0  \n",
      "28                                         0                          0  \n"
     ]
    }
   ],
   "source": [
    "results = json.load(open(\"llm_domain_coverage.json\"))\n",
    "analysis = analyze_domain_coverage(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235f128",
   "metadata": {},
   "source": [
    "### trying a different similarity threshold (threshold = 0.5, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ---- define thresholds you want to sweep ----\n",
    "    thresholds = [0.50, 0.60, 0.70, 0.75]\n",
    "\n",
    "    # ---- load your fixed data once ----\n",
    "    domains = load_domains()\n",
    "    indicators = flatten_indicators(domains)\n",
    "    index = build_faiss_index(indicators)\n",
    "    syllabi = load_syllabi()\n",
    "\n",
    "    all_results = {}  # store results in memory too\n",
    "\n",
    "    # ---- loop over thresholds ----\n",
    "    for thresh in thresholds:\n",
    "        global SIM_THRESHOLD\n",
    "        SIM_THRESHOLD = thresh\n",
    "\n",
    "        print(f\"\\n==============================================\")\n",
    "        print(f\" Running RAG pipeline with SIM_THRESHOLD = {thresh}\")\n",
    "        print(f\"==============================================\\n\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for syl in tqdm(syllabi):\n",
    "            res = compute_domain_coverage(index, indicators, syl)\n",
    "            results.append(res)\n",
    "\n",
    "        # ---- save results for this threshold ----\n",
    "        out_path = f\"llm_domain_coverage_sim_{thresh:.2f}.json\"\n",
    "        with open(out_path, \"w\") as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "        print(f\"Saved → {out_path}\")\n",
    "        all_results[thresh] = results\n",
    "\n",
    "    print(\"\\n=== Finished all threshold runs ===\")\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb68f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      " Running RAG pipeline with SIM_THRESHOLD = 0.5\n",
      "==============================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10/29 [03:21<05:44, 18.11s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19f6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vhbc-trey-repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
